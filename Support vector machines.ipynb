{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [The Tasks](#tt) <br>\n",
    "2. [Loading our Data and Libraries](#ld) <br>\n",
    "3. [SVM Linear Kernel](#rbf) <br>\n",
    "4. [SVM RBF Kernel](#rbf) <br>\n",
    "5. [Tuned Models](#tm) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tasks\n",
    "<a id=\"tt\" > "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the SVM model with a linear kernel - using the high-level OverFeat features\n",
    "\n",
    "- Tune the C parameter using grid search with cross-validation.\n",
    "- Collect the results in a DataFrame as described.\n",
    "- Find the C value with the best mean accuracy and print it.\n",
    "\n",
    "\n",
    "For the SVM model with an RBF kernel - using the high-level OverFeat features\n",
    "\n",
    "- Tune the C and γ parameters using grid search with cross-validation.\n",
    "- Collect the results in a DataFrame as described.\n",
    "- Find the combination of C and γ with the best mean accuracy and print it.\n",
    "\n",
    "For both models\n",
    "\n",
    "- You might want to use PCA as a preprocessing step. In any case, justify your choice.\n",
    "- Justify the choice of estimator, e.g., SVC, LinearSVC, SGDClassifier\n",
    "- Evaluate and report the accuracy on the 1,000 points from the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading/Preparing our Data and Libraries\n",
    "<a id=\"ld\" > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import LinearSVC, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our data countains dict_keys(['pixels', 'overfeat', 'labels', 'names', 'allow_pickle'])\n"
     ]
    }
   ],
   "source": [
    "with np.load('cifar4-train.npz', allow_pickle=False) as npz_file:\n",
    "    cifar4 = dict(npz_file.items())\n",
    "print('Our data countains {}'.format(cifar4.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_of = cifar4['overfeat']\n",
    "y = cifar4['labels']\n",
    "\n",
    "# Splitting our data into a train- and test set \n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_of, y, test_size=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Linear Kernel\n",
    "<a id=\"lk\" > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use PCA to speed up processing/prevent overfitting and set it to 200 retaining 90+% of the variance\n",
    "pca = PCA(n_components=200)\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('linearsvc', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=200, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('linearsvc', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'linearsvc__C': [0.0001, 0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv = GridSearchCV(pipe, {'linearsvc__C':[0.0001, 0.001,0.01,0.1,1,]}, \n",
    "                       cv=5,\n",
    "                       n_jobs=-1\n",
    "                      )\n",
    "\n",
    "grid_cv.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_linearsvc__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.83475</td>\n",
       "      <td>0.009764</td>\n",
       "      <td>0.860187</td>\n",
       "      <td>0.002414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.83325</td>\n",
       "      <td>0.008970</td>\n",
       "      <td>0.877438</td>\n",
       "      <td>0.002323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.82750</td>\n",
       "      <td>0.011505</td>\n",
       "      <td>0.890126</td>\n",
       "      <td>0.003350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.82500</td>\n",
       "      <td>0.010461</td>\n",
       "      <td>0.888500</td>\n",
       "      <td>0.003649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.78350</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>0.839378</td>\n",
       "      <td>0.005229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_linearsvc__C  mean_test_score  std_test_score  mean_train_score  \\\n",
       "0             0.0001          0.83475        0.009764          0.860187   \n",
       "1              0.001          0.83325        0.008970          0.877438   \n",
       "2               0.01          0.82750        0.011505          0.890126   \n",
       "3                0.1          0.82500        0.010461          0.888500   \n",
       "4                  1          0.78350        0.013469          0.839378   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.002414  \n",
       "1         0.002323  \n",
       "2         0.003350  \n",
       "3         0.003649  \n",
       "4         0.005229  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lin_svp = pd.DataFrame(grid_cv.cv_results_)[['param_linearsvc__C', \n",
    "                                                'mean_test_score', \n",
    "                                                'std_test_score',\n",
    "                                                'mean_train_score',\n",
    "                                                'std_train_score']]\n",
    "df_lin_svp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_lin_svp.plot(x = df_lin_svp['param_linearsvc__C'], y = df_lin_svp['mean_test_score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our best mean test accuracy was 0.835 and we achieved tjis with a C value of 0.0001\n"
     ]
    }
   ],
   "source": [
    "best = df_lin_svp['mean_test_score'].idxmax()\n",
    "\n",
    "print('our best mean test accuracy was {:.3f} and we achieved tjis with a C value of {}'\n",
    "      .format(df_lin_svp.loc[best, 'mean_test_score'], \n",
    "              df_lin_svp.loc[best, 'param_linearsvc__C']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM RBF Kernel\n",
    "<a id=\"rbf\" > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_rbf = SVC(kernel='rbf', random_state=0)\n",
    "\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('svc_rbf', svc_rbf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=200, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('svc_rbf', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'svc_rbf__C': [0.01, 0.1, 1, 10], 'svc_rbf__gamma': [0.0001, 0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_rbf = GridSearchCV(pipe, {'svc_rbf__C':[0.01, 0.1, 1, 10], \n",
    "                                  'svc_rbf__gamma':[0.0001, 0.001, 0.01, 0.1, 1]}, \n",
    "                           cv=5,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_cv_rbf.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_svc_rbf__C</th>\n",
       "      <th>param_svc_rbf__gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.45000</td>\n",
       "      <td>0.004404</td>\n",
       "      <td>0.450813</td>\n",
       "      <td>0.002341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.25575</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.255750</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.25575</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.255750</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.25575</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.255750</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25575</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.255750</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_svc_rbf__C param_svc_rbf__gamma  mean_test_score  std_test_score  \\\n",
       "0             0.01               0.0001          0.45000        0.004404   \n",
       "1             0.01                0.001          0.25575        0.000250   \n",
       "2             0.01                 0.01          0.25575        0.000250   \n",
       "3             0.01                  0.1          0.25575        0.000250   \n",
       "4             0.01                    1          0.25575        0.000250   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.450813         0.002341  \n",
       "1          0.255750         0.000063  \n",
       "2          0.255750         0.000063  \n",
       "3          0.255750         0.000063  \n",
       "4          0.255750         0.000063  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We safe the elements we care about in a data frame\n",
    "df_rbf_svp = pd.DataFrame(grid_cv_rbf.cv_results_)[['param_svc_rbf__C', \n",
    "                                                    'param_svc_rbf__gamma',\n",
    "                                                    'mean_test_score', \n",
    "                                                    'std_test_score',\n",
    "                                                    'mean_train_score',\n",
    "                                                    'std_train_score']]\n",
    "df_rbf_svp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our best accuracy was 0.840 and we achieved this with a C value of 10 and a gamme of 0.0001\n"
     ]
    }
   ],
   "source": [
    "best = df_rbf_svp['mean_test_score'].idxmax()\n",
    "\n",
    "print('Our best accuracy was {:.3f} and we achieved this with a C value of {} and a gamme of {}'\n",
    "      .format(df_rbf_svp.loc[best, 'mean_test_score'], \n",
    "              df_rbf_svp.loc[best, 'param_svc_rbf__C'], \n",
    "              df_rbf_svp.loc[best, 'param_svc_rbf__gamma'] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned Models\n",
    "<a id=\"tm\" > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Baseline (most frequent) accuracy on the training set is 0.256\n",
      "Our Baseline (most frequent) accuracy on the test set is 0.227\n"
     ]
    }
   ],
   "source": [
    "# Getting a baseline-accuracy based on the most frequent category\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_tr, y_tr)\n",
    "accuracy_tr = dummy.score(X_tr, y_tr)\n",
    "accuracy_te = dummy.score(X_te, y_te)\n",
    "\n",
    "print('Our Baseline (most frequent) accuracy on the training set is {:.3f}'.format(accuracy_tr))\n",
    "print('Our Baseline (most frequent) accuracy on the test set is {:.3f}'.format(accuracy_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Linear SVM model gives us an accuracy on the test set of 0.817\n",
      "Our RBF SVM model gives us an accuracy on the test set of 0.823\n"
     ]
    }
   ],
   "source": [
    "# Testing our models on the test-set\n",
    "acc_lin = grid_cv.score(X_te, y_te)\n",
    "acc_rbf = grid_cv_rbf.score(X_te, y_te)\n",
    "\n",
    "print ('Our Linear SVM model gives us an accuracy on the test set of {:.3f}'.format(acc_lin))\n",
    "print ('Our RBF SVM model gives us an accuracy on the test set of {:.3f}'.format(acc_rbf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
